================
device: cuda
latent_dim: 100
epochs: 100
learning_rate_G: 0.0002
learning_rate_D: 0.0002
dropout_p: 0.2
betas: (0.5,0.999)
seed: 451
================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
BasicGenerator                           [1, 1, 28, 28]            --
├─Sequential: 1-1                        [1, 1, 28, 28]            --
│    └─ConvTranspose2d: 2-1              [1, 128, 7, 7]            627,200
│    └─ReLU: 2-2                         [1, 128, 7, 7]            --
│    └─ConvTranspose2d: 2-3              [1, 64, 14, 14]           131,072
│    └─BatchNorm2d: 2-4                  [1, 64, 14, 14]           128
│    └─ReLU: 2-5                         [1, 64, 14, 14]           --
│    └─ConvTranspose2d: 2-6              [1, 64, 14, 14]           36,864
│    └─BatchNorm2d: 2-7                  [1, 64, 14, 14]           128
│    └─ReLU: 2-8                         [1, 64, 14, 14]           --
│    └─ConvTranspose2d: 2-9              [1, 32, 28, 28]           32,768
│    └─BatchNorm2d: 2-10                 [1, 32, 28, 28]           64
│    └─ReLU: 2-11                        [1, 32, 28, 28]           --
│    └─ConvTranspose2d: 2-12             [1, 32, 28, 28]           9,216
│    └─BatchNorm2d: 2-13                 [1, 32, 28, 28]           64
│    └─ReLU: 2-14                        [1, 32, 28, 28]           --
│    └─ConvTranspose2d: 2-15             [1, 1, 28, 28]            289
│    └─Tanh: 2-16                        [1, 1, 28, 28]            --
==========================================================================================
Total params: 837,793
Trainable params: 837,793
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 96.79
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 3.35
Estimated Total Size (MB): 4.61
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
BasicDiscriminator                       [1, 1, 1, 1]              --
├─Sequential: 1-1                        [1, 1, 1, 1]              --
│    └─Conv2d: 2-1                       [1, 32, 28, 28]           288
│    └─Dropout2d: 2-2                    [1, 32, 28, 28]           --
│    └─LeakyReLU: 2-3                    [1, 32, 28, 28]           --
│    └─Conv2d: 2-4                       [1, 64, 14, 14]           32,768
│    └─BatchNorm2d: 2-5                  [1, 64, 14, 14]           128
│    └─Dropout2d: 2-6                    [1, 64, 14, 14]           --
│    └─LeakyReLU: 2-7                    [1, 64, 14, 14]           --
│    └─Conv2d: 2-8                       [1, 64, 14, 14]           36,864
│    └─BatchNorm2d: 2-9                  [1, 64, 14, 14]           128
│    └─Dropout2d: 2-10                   [1, 64, 14, 14]           --
│    └─LeakyReLU: 2-11                   [1, 64, 14, 14]           --
│    └─Conv2d: 2-12                      [1, 128, 7, 7]            131,072
│    └─BatchNorm2d: 2-13                 [1, 128, 7, 7]            256
│    └─Dropout2d: 2-14                   [1, 128, 7, 7]            --
│    └─LeakyReLU: 2-15                   [1, 128, 7, 7]            --
│    └─Conv2d: 2-16                      [1, 128, 7, 7]            147,456
│    └─BatchNorm2d: 2-17                 [1, 128, 7, 7]            256
│    └─Dropout2d: 2-18                   [1, 128, 7, 7]            --
│    └─LeakyReLU: 2-19                   [1, 128, 7, 7]            --
│    └─Conv2d: 2-20                      [1, 1, 1, 1]              6,273
==========================================================================================
Total params: 355,489
Trainable params: 355,489
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 27.53
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.80
Params size (MB): 1.42
Estimated Total Size (MB): 2.23
==========================================================================================
epoch [  1/100], g_loss: 4.73056, d_loss: 0.64151
epoch [  2/100], g_loss: 1.43005, d_loss: 1.10683
epoch [  3/100], g_loss: 1.25399, d_loss: 1.15489
epoch [  4/100], g_loss: 1.23467, d_loss: 1.17363
epoch [  5/100], g_loss: 1.22687, d_loss: 1.18106
epoch [  6/100], g_loss: 1.18917, d_loss: 1.19638
epoch [  7/100], g_loss: 1.14799, d_loss: 1.20890
epoch [  8/100], g_loss: 1.11271, d_loss: 1.22259
epoch [  9/100], g_loss: 1.09869, d_loss: 1.23592
epoch [ 10/100], g_loss: 1.08966, d_loss: 1.23927
epoch [ 11/100], g_loss: 1.08575, d_loss: 1.24566
epoch [ 12/100], g_loss: 1.07969, d_loss: 1.24778
epoch [ 13/100], g_loss: 1.07194, d_loss: 1.25068
epoch [ 14/100], g_loss: 1.06635, d_loss: 1.25250
epoch [ 15/100], g_loss: 1.04958, d_loss: 1.26062
epoch [ 16/100], g_loss: 1.04938, d_loss: 1.26737
epoch [ 17/100], g_loss: 1.03966, d_loss: 1.26629
epoch [ 18/100], g_loss: 1.04520, d_loss: 1.26763
epoch [ 19/100], g_loss: 1.03674, d_loss: 1.27667
epoch [ 20/100], g_loss: 1.02742, d_loss: 1.27294
epoch [ 21/100], g_loss: 1.03003, d_loss: 1.27937
epoch [ 22/100], g_loss: 1.02295, d_loss: 1.27727
epoch [ 23/100], g_loss: 1.01559, d_loss: 1.28751
epoch [ 24/100], g_loss: 1.01118, d_loss: 1.28526
epoch [ 25/100], g_loss: 1.00735, d_loss: 1.28361
epoch [ 26/100], g_loss: 1.01631, d_loss: 1.28475
epoch [ 27/100], g_loss: 0.99878, d_loss: 1.28931
epoch [ 28/100], g_loss: 1.00201, d_loss: 1.29282
epoch [ 29/100], g_loss: 1.00809, d_loss: 1.28729
epoch [ 30/100], g_loss: 1.00252, d_loss: 1.28912
epoch [ 31/100], g_loss: 0.99401, d_loss: 1.29422
epoch [ 32/100], g_loss: 0.99561, d_loss: 1.29683
epoch [ 33/100], g_loss: 0.98955, d_loss: 1.29607
epoch [ 34/100], g_loss: 0.99453, d_loss: 1.29473
epoch [ 35/100], g_loss: 0.98936, d_loss: 1.29396
epoch [ 36/100], g_loss: 0.99117, d_loss: 1.29299
epoch [ 37/100], g_loss: 0.99630, d_loss: 1.29535
epoch [ 38/100], g_loss: 0.98900, d_loss: 1.29494
epoch [ 39/100], g_loss: 0.98489, d_loss: 1.29811
epoch [ 40/100], g_loss: 0.98340, d_loss: 1.29489
epoch [ 41/100], g_loss: 0.98601, d_loss: 1.30026
epoch [ 42/100], g_loss: 0.97862, d_loss: 1.29290
epoch [ 43/100], g_loss: 0.98259, d_loss: 1.29662
epoch [ 44/100], g_loss: 0.97275, d_loss: 1.29912
epoch [ 45/100], g_loss: 0.98208, d_loss: 1.30078
epoch [ 46/100], g_loss: 0.97944, d_loss: 1.29690
epoch [ 47/100], g_loss: 0.97859, d_loss: 1.30378
epoch [ 48/100], g_loss: 0.98332, d_loss: 1.29689
epoch [ 49/100], g_loss: 0.97818, d_loss: 1.30069
epoch [ 50/100], g_loss: 0.97670, d_loss: 1.30370
epoch [ 51/100], g_loss: 0.97072, d_loss: 1.30401
epoch [ 52/100], g_loss: 0.97695, d_loss: 1.29991
epoch [ 53/100], g_loss: 0.97413, d_loss: 1.30224
epoch [ 54/100], g_loss: 0.96480, d_loss: 1.30381
epoch [ 55/100], g_loss: 0.96443, d_loss: 1.30366
epoch [ 56/100], g_loss: 0.96562, d_loss: 1.30266
epoch [ 57/100], g_loss: 0.97138, d_loss: 1.30402
epoch [ 58/100], g_loss: 0.97273, d_loss: 1.30113
epoch [ 59/100], g_loss: 0.97501, d_loss: 1.29925
epoch [ 60/100], g_loss: 0.96559, d_loss: 1.30333
epoch [ 61/100], g_loss: 0.97058, d_loss: 1.30077
epoch [ 62/100], g_loss: 0.97691, d_loss: 1.30151
epoch [ 63/100], g_loss: 0.95708, d_loss: 1.30479
epoch [ 64/100], g_loss: 0.97515, d_loss: 1.30163
epoch [ 65/100], g_loss: 0.96646, d_loss: 1.30663
epoch [ 66/100], g_loss: 0.96522, d_loss: 1.30037
epoch [ 67/100], g_loss: 0.96291, d_loss: 1.30532
epoch [ 68/100], g_loss: 0.96523, d_loss: 1.30004
epoch [ 69/100], g_loss: 0.96999, d_loss: 1.30189
epoch [ 70/100], g_loss: 0.96579, d_loss: 1.30219
epoch [ 71/100], g_loss: 0.96856, d_loss: 1.30403
epoch [ 72/100], g_loss: 0.96938, d_loss: 1.30844
epoch [ 73/100], g_loss: 0.97390, d_loss: 1.30573
epoch [ 74/100], g_loss: 0.96501, d_loss: 1.30456
epoch [ 75/100], g_loss: 0.96355, d_loss: 1.30331
epoch [ 76/100], g_loss: 0.96078, d_loss: 1.30419
epoch [ 77/100], g_loss: 0.97132, d_loss: 1.30491
epoch [ 78/100], g_loss: 0.95886, d_loss: 1.29962
epoch [ 79/100], g_loss: 0.96588, d_loss: 1.30188
epoch [ 80/100], g_loss: 0.97205, d_loss: 1.29623
epoch [ 81/100], g_loss: 0.97054, d_loss: 1.30169
epoch [ 82/100], g_loss: 0.97599, d_loss: 1.30301
epoch [ 83/100], g_loss: 0.97176, d_loss: 1.30251
epoch [ 84/100], g_loss: 0.96916, d_loss: 1.30113
epoch [ 85/100], g_loss: 0.96508, d_loss: 1.30383
epoch [ 86/100], g_loss: 0.96418, d_loss: 1.30163
epoch [ 87/100], g_loss: 0.97374, d_loss: 1.29950
epoch [ 88/100], g_loss: 0.97422, d_loss: 1.29912
epoch [ 89/100], g_loss: 0.98240, d_loss: 1.30092
epoch [ 90/100], g_loss: 0.97619, d_loss: 1.29657
epoch [ 91/100], g_loss: 0.98425, d_loss: 1.29736
epoch [ 92/100], g_loss: 0.97698, d_loss: 1.29706
epoch [ 93/100], g_loss: 0.96867, d_loss: 1.30491
epoch [ 94/100], g_loss: 0.97112, d_loss: 1.29599
epoch [ 95/100], g_loss: 0.97673, d_loss: 1.29925
epoch [ 96/100], g_loss: 0.97989, d_loss: 1.29845
epoch [ 97/100], g_loss: 0.97807, d_loss: 1.29974
epoch [ 98/100], g_loss: 0.98335, d_loss: 1.29344
epoch [ 99/100], g_loss: 0.97383, d_loss: 1.29737
epoch [100/100], g_loss: 0.98587, d_loss: 1.29022
