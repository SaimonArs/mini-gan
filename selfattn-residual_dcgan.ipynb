{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9850e97-90ca-4464-9a40-9abf0268a2a6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a14211-5dfd-4356-a18e-79224476870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bf22f96-70b1-4a3a-8bea-0dcec20ed36a",
   "metadata": {},
   "source": [
    "l1 = nn.ConvTranspose2d(128, 64, kernel_size=7, stride=1, padding=0)\n",
    "l2 = nn.Conv2d(1, 128, kernel_size=3, stride=1, padding=1)\n",
    "l3 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1)\n",
    "X = torch.rand(size=(128, 1, 1))\n",
    "l3(l1(X)).shape\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "929274aa-0c30-4577-9200-eaba1f306495",
   "metadata": {},
   "source": [
    "l1 = nn.ConvTranspose2d(128, 256, kernel_size=7, stride=1, padding=0, bias=False)\n",
    "            \n",
    "l2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "l3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            \n",
    "l4 = nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "X = torch.rand(size=(128, 1, 1))\n",
    "l4(l3(l2(l1(X)))).shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c99cb136-aef8-4e0f-bd3b-6823ba8eae82",
   "metadata": {},
   "source": [
    "l1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "l2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            \n",
    "l3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            \n",
    "l4 = nn.Conv2d(256, 1, kernel_size=7, stride=1, padding=0, bias=False)\n",
    "X = torch.rand(size=(1, 28, 28))\n",
    "\n",
    "l4(l3(l2(l1(X)))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93d4037-a696-40c2-a44a-432ae1debf76",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26c113-4e4d-4cc7-92d2-22c25f00c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT = \"A\" # Вариант - модели (для разделения моделей с разными гиперпараметрами) result/VARIANT+SEED/\n",
    "SEED = 451 # Для получения предсказуемых результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9a486-09eb-4d6c-a7f8-683ca41d329a",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8d269-c583-491c-ae45-976b635f5307",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"selfattn_residual_dcgan\"\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "torch.set_default_device(DEVICE)\n",
    "\n",
    "LATENT_DIM = 100\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE_G = 0.0002\n",
    "LEARNING_RATE_D = 0.0002\n",
    "BETA_1 = 0.5\n",
    "BETA_2 = 0.999\n",
    "DROPOUT_P = 0.2\n",
    "\n",
    "# Пути для сохранения\n",
    "SAVE_DIR = \"./result\"\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "RESULT_DIR = f\"{SAVE_DIR}/{MODEL_NAME}/{VARIANT}{SEED}\"\n",
    "GIF_DIR = f\"{RESULT_DIR}/gif\"\n",
    "\n",
    "Path(RESULT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(GIF_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e951a-343a-4f82-82e4-24a4e9a87645",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(DEVICE) == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e18927-eb90-4d99-98e7-b6111a2d1497",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6b8ea-59d5-4998-a9a0-604ff5a0cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(msg, log=f\"{RESULT_DIR}/hist.log\"):\n",
    "    with open(log, \"a\") as f:\n",
    "        f.write(msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e6ffa-4bc6-4848-9ad7-5c18d9594205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models():\n",
    "     \"\"\"Сохранение моделей\"\"\"\n",
    "     torch.save(generator.state_dict(),\n",
    "               f\"{RESULT_DIR}/generator.pth\")\n",
    "     torch.save(discriminator.state_dict(),\n",
    "               f\"{RESULT_DIR}/discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90373d4a-20f7-457b-9d86-3d070e0aa1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gan_losses(generator_losses, discriminator_losses, model_name=\"GAN\", save_path=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(generator_losses, label='Generator loss', color='red')\n",
    "    plt.plot(discriminator_losses, label='Discriminator loss', color='blue')\n",
    "    \n",
    "    plt.title(f'{model_name} losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(f\"{save_path}/losses\", bbox_inches='tight')\n",
    "        print(f\"Save path: {save_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6040a96-892c-43c3-b8e6-ad8d17ec5318",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94fe06-f7d7-4376-9189-8d6d68bcdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "write_log(\"=\"*16)\n",
    "write_log(f\"device: {DEVICE}\")\n",
    "write_log(f\"latent_dim: {LATENT_DIM}\")\n",
    "write_log(f\"epochs: {EPOCHS}\")\n",
    "write_log(f\"learning_rate_G: {LEARNING_RATE_G}\")\n",
    "write_log(f\"learning_rate_D: {LEARNING_RATE_D}\")\n",
    "write_log(f\"dropout_p: {DROPOUT_P}\")\n",
    "write_log(f\"betas: ({BETA_1},{BETA_2})\")\n",
    "write_log(f\"seed: {SEED}\")\n",
    "write_log(\"=\"*16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273a0be-e224-4a0d-9560-a2585f4ceea5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61197d-7557-4f10-bf44-20f0d7e5a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataloader(batch_size=None, data_dir='./data'):\n",
    "    \"\"\"Загрузка и подготовка датасета MNIST\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=data_dir,\n",
    "        train=True, \n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        generator=torch.Generator(device=DEVICE),\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e29cdc-2adb-4468-b963-ee68485a20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_mnist_dataloader(batch_size=BATCH_SIZE, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392789db-f8f2-4579-a89d-bc0c7571427f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59124ea8-369a-438a-a529-426af554a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.Wf = nn.Conv2d(ch, ch//2, 1)\n",
    "        self.Wg = nn.Conv2d(ch, ch//2, 1)\n",
    "        self.Wh = nn.Conv2d(ch, ch, 1)\n",
    "        self.gamma = nn.Parameter(torch.full((1, 1), 0.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        N = H * W\n",
    "\n",
    "        f = self.Wf(x).view(B, -1, N).permute(0, 2, 1) # (B, N, C')\n",
    "        g = self.Wg(x).view(B, -1, N) # (B, C', N)\n",
    "        h = self.Wh(x).view(B, -1, N) # (B, C, N)\n",
    "\n",
    "        s = f@g # (B, N, N)\n",
    "        beta = torch.softmax(s, dim=-1) # (B, N, N)\n",
    "        attn = h@beta.permute(0, 2, 1) # (B, C, N)\n",
    "\n",
    "        out = (self.gamma * attn + x.view(B, C, N)).view(B, C, H, W)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, ch, dropout_p=0.0):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fblock = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ch),\n",
    "            nn.Dropout2d(dropout_p),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(ch, ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ch),\n",
    "            nn.Dropout2d(dropout_p),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fblock(x)\n",
    "        return out + x\n",
    "\n",
    "n = 32\n",
    "class BasicGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(BasicGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(latent_dim, n*4, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(n*4, n*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n*2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "\n",
    "            ResidualBlock(n*2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            SelfAttention(n*2),\n",
    "            \n",
    "            nn.ConvTranspose2d(n*2, n, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            ResidualBlock(n),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(n, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class BasicDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, n, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.Dropout2d(DROPOUT_P),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n, n*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n*2),\n",
    "            nn.Dropout2d(DROPOUT_P),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            ResidualBlock(n*2, dropout_p=DROPOUT_P),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(n*2, n*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n*4),\n",
    "            nn.Dropout2d(DROPOUT_P),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            ResidualBlock(n*4, dropout_p=DROPOUT_P),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(n*4, 1, kernel_size=7, stride=1, padding=0),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288d520-5a60-4e4e-b202-038246e12575",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = BasicGenerator(latent_dim=LATENT_DIM)\n",
    "sm_g = summary(generator, input_size=(1, LATENT_DIM, 1, 1), device=DEVICE)\n",
    "sm_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2bfbf0-b117-44c3-a8b8-f15e30354f02",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = BasicDiscriminator()\n",
    "sm_d = summary(discriminator, input_size=(1, 1, 28, 28), device=DEVICE)\n",
    "sm_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e2f28-67a3-4e78-a065-3362bd37a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_log(str(sm_g))\n",
    "write_log(str(sm_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878a8c4-56ee-4d8e-99f2-bf24b2cd3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers\n",
    "g_optimizer = optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=LEARNING_RATE_G,\n",
    "    betas=(BETA_1, BETA_2)\n",
    ")\n",
    "\n",
    "d_optimizer = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=LEARNING_RATE_D,\n",
    "    betas=(BETA_1, BETA_2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46533b05-6919-4656-82d1-f6e977d86864",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92a104-c938-45ec-9c7f-f98dd81957d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1678ae-bdb1-4a55-8aef-529ad195507b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def d_step(real_images, batch_size):\n",
    "    noise = torch.randn(batch_size, LATENT_DIM, 1, 1)\n",
    "\n",
    "    fake_label = torch.zeros(batch_size, 1, 1, 1)\n",
    "    real_label = torch.full((batch_size, 1, 1, 1), 0.9).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "    discriminator.train()\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    fake_pred = discriminator(fake_images.detach())\n",
    "    d_loss_fake = criterion(fake_pred, fake_label)\n",
    "    \n",
    "    real_pred = discriminator(real_images)\n",
    "    d_loss_real = criterion(real_pred, real_label) \n",
    "   \n",
    "    d_loss =  d_loss_fake + d_loss_real \n",
    "    \n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "    return d_loss.item()\n",
    "\n",
    "def g_step(batch_size):\n",
    "    noise = torch.randn(batch_size, LATENT_DIM, 1, 1)\n",
    "    \n",
    "    real_label = torch.ones(batch_size, 1, 1, 1)\n",
    "\n",
    "    generator.train()\n",
    "    g_optimizer.zero_grad()\n",
    "\n",
    "    fake_images = generator(noise)\n",
    "    fake_pred = discriminator(fake_images)\n",
    "\n",
    "    g_loss = criterion(fake_pred, real_label)\n",
    "\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    return g_loss.item()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033359a-88e7-4443-b5b6-996652d03b93",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adbf4b-266e-495e-be20-02d4f894a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_losses_d = []\n",
    "history_losses_g = []\n",
    "\n",
    "#\n",
    "fixed_noise = torch.randn(64, LATENT_DIM, 1, 1).to(DEVICE)\n",
    "#\n",
    "\n",
    "for epoch in trange(EPOCHS, unit=\"epoch\"):\n",
    "    num_batches = 0\n",
    "    epoch_d_loss = 0\n",
    "    epoch_g_loss = 0\n",
    "\n",
    "    \n",
    "    tq = tqdm(\n",
    "        enumerate(dataloader),\n",
    "        total=len(dataloader),\n",
    "        leave=False,\n",
    "        unit=\"batch\",)\n",
    "    \n",
    "    for i, (real_images, _) in tq :\n",
    "        real_images = real_images.to(DEVICE)\n",
    "        batch_size = real_images.size(0)\n",
    "        epoch_d_loss += d_step(real_images, batch_size)\n",
    "        epoch_g_loss += g_step(batch_size)\n",
    "        num_batches += 1\n",
    "\n",
    "    history_losses_d.append(epoch_d_loss / num_batches)\n",
    "    history_losses_g.append(epoch_g_loss / (num_batches))\n",
    "    \n",
    "\n",
    "    info = f'epoch [{(epoch+1):>3}/{EPOCHS}], ' + \\\n",
    "         f'g_loss: {history_losses_g[-1]:.5f}, ' + \\\n",
    "         f'd_loss: {history_losses_d[-1]:.5f}'\n",
    "\n",
    "    print(info)\n",
    "\n",
    "    write_log(info)\n",
    "    generator.eval() \n",
    "    with torch.no_grad():\n",
    "        gen = generator(fixed_noise)\n",
    "        save_image(gen.view(gen.size(0), 1, 28, 28),\n",
    "                  f\"{GIF_DIR}/{epoch+1}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40ad1b-a44f-43d3-86ae-9ae34408f4e9",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd016b2b-30f6-4ccf-83ed-413ce74a9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b7e90-3517-47bb-8570-0c666611a3b1",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be24521-7a22-4347-b42b-e9441c02450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan_losses(history_losses_g, history_losses_d, MODEL_NAME, RESULT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
