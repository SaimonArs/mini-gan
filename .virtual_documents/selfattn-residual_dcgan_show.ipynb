


import torch
from torch import nn 

from torchinfo import summary

import numpy as np

import matplotlib.pyplot as plt

import random
from pathlib import Path
from PIL import Image

from IPython.display import display, HTML





VARIANT = "A" # Вариант - модели (для разделения моделей с разными гиперпараметрами) result/VARIANT+SEED/
SEED = 451 # Для получения предсказуемых результатов





MODEL_NAME = "selfattn_residual_dcgan"

DEVICE = torch.device(
    "cuda" if torch.cuda.is_available() else "cpu"
)
# DEVICE = torch.device("cpu")
torch.set_default_device(DEVICE)

BATCH_SIZE = 256
DROPOUT_P = 0.2
LATENT_DIM = 100

SAVE_DIR = "./result"
DATA_DIR = "./data"

RESULT_DIR = f"{SAVE_DIR}/{MODEL_NAME}/{VARIANT}{SEED}"
GIF_DIR = f"{RESULT_DIR}/gif"

Path(RESULT_DIR).mkdir(parents=True, exist_ok=True)
Path(GIF_DIR).mkdir(parents=True, exist_ok=True)


if str(DEVICE) == 'cuda':
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
torch.manual_seed(SEED)
np.random.seed(SEED)
random.seed(SEED)





def load_models():
     """Загрузка моделей"""
     generator.load_state_dict(
         torch.load(f"{RESULT_DIR}/generator.pth")
     )
     discriminator.load_state_dict(
         torch.load(f"{RESULT_DIR}/discriminator.pth")
     )


def create_gif(
    image_paths,
    output_path,
    duration_ms = 500,
    loop = 0,
    optimize = True
):
    if not image_paths:
        raise ValueError("image_paths cannot be empty")

    frames = []
    for p in image_paths:
        im = Image.open(p).convert("P", palette=Image.ADAPTIVE)
        frames.append(im)

    first, *rest = frames
    first.save(
        output_path,
        save_all=True,
        append_images=rest,
        duration=duration_ms,
        loop=loop,
        optimize=optimize,
        disposal=2
    )



def plot_res_64(imgs, label, title, figsize=(20, 16)):
    fig, axs = plt.subplots(8, 8, figsize=figsize)
    axs = [axs[i//8][i % 8] for i in range(64)]

    for ax, img, pred in zip(axs, imgs, label):
        ax.imshow(img[0], cmap='gray', vmin=0, vmax=1)
        ax.set_title(f'{pred:.4f}', fontsize=10, pad=2)
        ax.axis('off')

    plt.suptitle(f'{title}',
                 fontsize=20, fontweight='bold', y=0.95)

    plt.plot()





print(f"device: {DEVICE}")





class SelfAttention(nn.Module):
    def __init__(self, ch):
        super(SelfAttention, self).__init__()
        self.Wf = nn.Conv2d(ch, ch//2, 1)
        self.Wg = nn.Conv2d(ch, ch//2, 1)
        self.Wh = nn.Conv2d(ch, ch, 1)
        self.gamma = nn.Parameter(torch.full((1, 1), 0.))

    def forward(self, x):
        B, C, H, W = x.shape
        N = H * W

        f = self.Wf(x).view(B, -1, N).permute(0, 2, 1) # (B, N, C')
        g = self.Wg(x).view(B, -1, N) # (B, C', N)
        h = self.Wh(x).view(B, -1, N) # (B, C, N)

        s = f@g # (B, N, N)
        beta = torch.softmax(s, dim=-1) # (B, N, N)
        attn = h@beta.permute(0, 2, 1) # (B, C, N)

        out = (self.gamma * attn + x.view(B, C, N)).view(B, C, H, W)

        return out

class ResidualBlock(nn.Module):
    def __init__(self, ch, dropout_p=0.0):
        super(ResidualBlock, self).__init__()
        self.fblock = nn.Sequential(
            nn.Conv2d(ch, ch, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(ch),
            nn.Dropout2d(dropout_p),
            nn.LeakyReLU(0.2),

            nn.Conv2d(ch, ch, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(ch),
            nn.Dropout2d(dropout_p),
        )

    def forward(self, x):
        out = self.fblock(x)
        return out + x

n = 32
class BasicGenerator(nn.Module):
    def __init__(self, latent_dim=100):
        super(BasicGenerator, self).__init__()
        self.model = nn.Sequential(
            
            nn.ConvTranspose2d(latent_dim, n*4, kernel_size=7, stride=1, padding=0, bias=False),
            nn.ReLU(),
            
            nn.ConvTranspose2d(n*4, n*2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n*2),
            nn.ReLU(),
            

            ResidualBlock(n*2),
            nn.ReLU(),

            SelfAttention(n*2),
            
            nn.ConvTranspose2d(n*2, n, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n),
            nn.ReLU(),

            ResidualBlock(n),
            nn.ReLU(),

            nn.ConvTranspose2d(n, 1, kernel_size=3, stride=1, padding=1),
            nn.Tanh()
        )
    
    def forward(self, x):
        return self.model(x)

class BasicDiscriminator(nn.Module):
    def __init__(self):
        super(BasicDiscriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, n, kernel_size=3, stride=1, padding=1, bias=False),
            nn.Dropout2d(DROPOUT_P),
            nn.LeakyReLU(0.2),

            nn.Conv2d(n, n*2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n*2),
            nn.Dropout2d(DROPOUT_P),
            nn.LeakyReLU(0.2),
            
            ResidualBlock(n*2, dropout_p=DROPOUT_P),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(n*2, n*4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(n*4),
            nn.Dropout2d(DROPOUT_P),
            nn.LeakyReLU(0.2),

            ResidualBlock(n*4, dropout_p=DROPOUT_P),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(n*4, 1, kernel_size=7, stride=1, padding=0),
        )
    
    def forward(self, x):
        return self.model(x)


generator = BasicGenerator(latent_dim=LATENT_DIM)
sm_g = summary(generator, input_size=(1, LATENT_DIM, 1, 1), device=DEVICE)
sm_g


discriminator = BasicDiscriminator()
sm_d = summary(discriminator, input_size=(1, 1, 28, 28), device=DEVICE)
sm_d





load_models()
generator.eval()
discriminator.eval()
print('load')





pngs = list(Path(GIF_DIR).glob("*.png"))
create_gif(pngs, RESULT_DIR + "/res.gif")


display(HTML(f'<img src="{RESULT_DIR}/res.gif" width="700">'))





s = SEED
torch.manual_seed(s)
noise = (torch.randn(BATCH_SIZE, LATENT_DIM, 1, 1)) 
generator.eval()
with torch.no_grad():
    gen = generator(noise)[0:64]
plot_res_64(gen.cpu().numpy(),
            nn.Sigmoid()(discriminator(gen)).reshape(-1).cpu().tolist(),
            MODEL_NAME+f" - Seed: {s}")
plt.savefig(f"{RESULT_DIR}/{s}", bbox_inches='tight')


s += 1
torch.manual_seed(s)
noise = (torch.randn(BATCH_SIZE, LATENT_DIM, 1, 1)) 
generator.eval()
with torch.no_grad():
    gen = generator(noise)[0:64]
plot_res_64(gen.cpu().numpy(),
            nn.Sigmoid()(discriminator(gen)).reshape(-1).cpu().tolist(),
            MODEL_NAME+f" - Seed: {s}")
plt.savefig(f"{RESULT_DIR}/{s}", bbox_inches='tight')


s += 1
torch.manual_seed(s)
noise = (torch.randn(BATCH_SIZE, LATENT_DIM, 1, 1)) 
generator.eval()
with torch.no_grad():
    gen = generator(noise)[0:64]
plot_res_64(gen.cpu().numpy(),
            nn.Sigmoid()(discriminator(gen)).reshape(-1).cpu().tolist(),
            MODEL_NAME+f" - Seed: {s}")
plt.savefig(f"{RESULT_DIR}/{s}", bbox_inches='tight')


s += 1
torch.manual_seed(s)
noise = (torch.randn(BATCH_SIZE, LATENT_DIM, 1, 1)) 
generator.eval()
with torch.no_grad():
    gen = generator(noise)[0:64]
plot_res_64(gen.cpu().numpy(),
            nn.Sigmoid()(discriminator(gen)).reshape(-1).cpu().tolist(),
            MODEL_NAME+f" - Seed: {s}")
plt.savefig(f"{RESULT_DIR}/{s}", bbox_inches='tight')
